{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from anomaly_detection.main import setup_paths\n",
    "from anomaly_detection.trainers.trainer import Trainer\n",
    "from anomaly_detection.utils.tensors import *\n",
    "from data.hdfs_series import HDFSEvents\n",
    "from data.dataset import HDFSEventsDataset\n",
    "from models.deeplog import DeepLog\n",
    "from utils.torch import save_model_info\n",
    "from loguru import logger\n",
    "\n",
    "# Configure loguru logger\n",
    "logger.add(\"debug.log\", level=\"DEBUG\")\n",
    "\n",
    "save_folder, main_repo = setup_paths()\n",
    "\n",
    "# Check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model configuration and instantiation\n",
    "model_name = \"deeplog\"\n",
    "configs = {\n",
    "    \"deeplog\": {\n",
    "        \"train_val_split\": 0.8,\n",
    "        \"window_size\": 10,\n",
    "        \"max_iters\": 1000,\n",
    "        \"eval_interval\": 100,\n",
    "        \"input_size\": 1,\n",
    "        \"hidden_size\": 64,\n",
    "        \"num_layers\": 2,\n",
    "        \"output_size\": 28,\n",
    "        \"batch_size\": 16,\n",
    "    },\n",
    "}\n",
    "hp = configs[model_name]\n",
    "model = DeepLog(input_size=hp[\"input_size\"], hidden_size=hp[\"hidden_size\"], num_layers=hp[\"num_layers\"], output_size=hp[\"output_size\"]).to(device)\n",
    "\n",
    "# Process dataset\n",
    "events = HDFSEvents.from_text_file(main_repo / 'data/hdfs/hdfs_train', nrows=100)\n",
    "dataset = HDFSEventsDataset(events, window_size=hp[\"window_size\"])\n",
    "\n",
    "# Split dataset\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * hp[\"train_val_split\"])\n",
    "val_size = total_size - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=hp[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=hp[\"batch_size\"], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------\n",
      "Tensor Info:\n",
      "Shape: torch.Size([16, 10])\tDatatype: torch.int64\n",
      "-------------------\n",
      "\n",
      "\n",
      "-------------------\n",
      "Tensor Info:\n",
      "Shape: torch.Size([16])\tDatatype: torch.int64\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print dataset of one data point\n",
    "xs, xy = next(iter(train_loader))\n",
    "# Print sizes of xs, xy\n",
    "pretty_print_tensor(xs)\n",
    "pretty_print_tensor(xy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
